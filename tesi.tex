\documentclass[corpo=11pt, stile=classica, tipotesi=custom,
greek, evenboxes, english]{toptesi}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{hyperref}
\hypersetup{%
	pdfpagemode={UseOutlines},
	bookmarksopen,
	pdfstartview={FitH},
	colorlinks,
	linkcolor={blue},
	citecolor={blue},
	urlcolor={blue}
}

\usepackage{geometry} %for the margins
\newcommand\fillin[1][4cm]{\makebox[#1]{\dotfill}} %for the dotted line in the frontispiace

\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1} } %to vetical align numbers in tables, along the decimal dot

\usepackage{amsmath}







\usepackage{amsmath, amssymb, amsthm}
\usepackage{esint}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{systeme}
\usepackage{mathtools}
\hypersetup{colorlinks, linkcolor=blue, citecolor=blue}
\usepackage{biblatex}
\addbibresource{bibliografia.bib}


\numberwithin{equation}{chapter}
\newtheorem{teo}{Theorem}[chapter] %in questo modo la numerazione ricomincia da capo ad ogni nuovo capitolo
\newtheorem{defi}[teo]{Definition}
\newtheorem{lem}[teo]{Lemma}
\newtheorem{cor}[teo]{Corollary}
\newtheorem{prop}[teo]{Proposition}
\newtheorem{es}[teo]{Example}

\newcommand{\R}{\mathbb{R}} %scorciatoia per R
\newcommand{\V}{\mathcal{V}} %STFT
\newcommand{\dxdo}{dxd\omega}
\newcommand{\notazione}{\underline{\textbf{Remark Notazionale}}}
\newcommand{\Log}{\ensuremath{\text{Log}_-}}
\newcommand{\finire}{\fbox{\LARGE DA FINIRE}}
\newcommand{\pfrac}[2]{\dfrac{\partial #1}{\partial #2}}

\begin{document}
	
\input{./title.tex}

\tableofcontents

\sommario

\chapter{Introduction}

\chapter{Basics of functional analysis}

\chapter{Short-Time Fourier Transform}
\section{STFT}
\subsection{Properties of STFT}
\section{Fock Space and Bargmann Transform}
\section{Faber-Krahn Inequality for the STFT}

Theorem from \cite{nicolatilli_fk}
\begin{teo}\label{faberkrahn}
	For every $f \in L^2(\R^d)$ such that $\|f\|_{L^2} = 1$ and every measurable subset $\Omega \subset \R^{2d}$ with finite measure we have
	\begin{equation*}
		\int_{\Omega}  |\V f(x,\omega)|^2 \dxdo \leq G(|\Omega|)
	\end{equation*}
	where $G(s)$ is given by
	\begin{equation}\label{G}
		G(s) \coloneqq \int_0^s e^{\left(-d!\tau\right)^{1/d}} d\tau
	\end{equation}
\end{teo}


\chapter{Localization Operators}
\section{Definition and properties}
\section{Eigenvalues and eigenfunctions}

\chapter{Recent results from Nicola-Tilli}
\section{Case $q=+\infty$}
\section{Generic case}
Let's now consider the case where both $p$ and $q$ are neither 1 or $+\infty$. The result presented in \cite{nicolatilli_norm} include the case ...
\begin{equation*}
	\| L_F\|_{L_2 \rightarrow L_2} \leq \min\{\kappa_p^{d\kappa_p}A, \, \kappa_q^{d\kappa_q}B\}
\end{equation*}
Suppose that the minimum is given by $\kappa_p^{d\kappa_p}A$, therefore
\begin{equation*}
	\kappa_p^{d\kappa_p}A \leq \kappa_q^{d\kappa_q}B \iff \dfrac{B}{A} \geq \left(\dfrac{\kappa_p^{\kappa_p}}{\kappa_q^{\kappa_q}}\right)^d
\end{equation*}
We can check if the solution of the problem with just the $L^p$ bound solves also the problem with both bounds, that is $F\|_{L^q} \leq B$, where $F$ is given by ...
\begin{align*}
	\| F \|_{L^q}^q &= \int_{\R^{2d}} |F(z)|^q dz = ... = \lambda^q \left(\dfrac{p-1}{q}\right)^d
\end{align*}
Since we want $F$ to satisfy the $L^q$ constraint we should have
\begin{equation*}
	\dfrac{B}{A} \geq \kappa_p^{d\left(\frac1q - \frac1p\right)}\left(\dfrac{p}{q}\right)^{\frac{d}{q}}
\end{equation*}
It would be nice if this bound was less restrictive than the first one. Unfortunately that's not the case, in fact it's always true that
\begin{equation*}
	\left(\dfrac{p'}{q'}\right)^{\frac1{q'}} \left(\dfrac{p}{q}\right)^{\frac1q} \geq 1
\end{equation*}

Following the path in \cite{nicolatilli_norm} we obtain ...\\
\begin{equation*}
	G'(u(t)) = \lambda_1 t^{p-1} + \lambda_2 t^{q-1} \implies u(t) = \dfrac{1}{d!}\left[-\log\left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right)\right]^d, \ t \in (0,M)
\end{equation*}
Our main goal now is to show that multipliers $\lambda_1, \lambda_2$ are unique and both positive.

The easiest fact to prove is that both multipliers are not 0. In fact if one, say $\lambda_2$, was 0, we would obtain that the solution of our problem is the same as the one with just the $L^p$ bound. But we already know that this function does not satisfy the $L^q$ constraint hence it is impossible that $\lambda_2=0$.

Suppose now that one of the multipliers, say always $\lambda_2$, is negative. Consider an interval $[a,b] \subset (0,M)$ and a variation $\eta \in L^{\infty}(0,M)$ supported in $[a,b]$. Thanks to the Gram-Schmidt process we can construct a variation orthogonal to $t^{p-1}$. Since $\eta$ is arbitrary we can suppose that it is not orthogonal to $t^{q-1}$, in particular we can suppose that $\int_{a}^{b}t^{q-1}\eta(t)dt <0$. Therefore the directional derivative of $G$ along $\eta$ is:
\begin{align*}
	\int_{a}^{b} G'(u(t))\eta(t)dt &= \int_{a}^{b} (\lambda_1 t^{p-1} + \lambda_2 t^{q-1})\eta(t)dt = \\
									   &= \lambda_2 \int_{a}^{b} t^{q-1} \eta(t)dt > 0
\end{align*}
which contradicts the fact that $u$ is a maximizer.

Now that we now that both multipliers are positive we can prove that $u$ is continuous, which is equivalent to say that $M=T$, where $T$ is the unique positive number such that $\lambda_1 T^{p-1} + \lambda_2 T^{q-1} = 1$ (uniqueness of $T$ follows from the positivity of multipliers).\\
We start supposing that $M < T$ which means that $\lim_{t \rightarrow M^-} u(t) > 0$. Consider the following variation 
\begin{equation*}
	\eta(t) = \left\{
	\begin{aligned}
		-1 + \alpha \frac{t}{M} + \beta,\quad & t \in (M-M\delta,M)\\
		1,\quad					   & t \in (M,M+M\delta)\\
		0,\quad				   & \text{otherwise}
	\end{aligned}\right.
\end{equation*}
where $\delta>0$ is small enough so that $M-M\delta >0$ and $M+M\delta < T$ while $\alpha$ and $\beta$ are constants, depending on $\delta$, to be found. Since we want this to be an admissible variation we need to impose that $\eta$ is orthogonal to $t^{p-1}$ and $t^{q-1}$. For example, the first condition is:
\begin{align*}
	0 &= \int_{M-M\delta}^{M+M\delta} t^{p-1} \eta(t) dt = -\int_{M-M\delta}^M t^{p-1}dt + \int_{M-M\delta}^M t^{p-1}\left(\alpha \frac{t}{M} + \beta\right) dt + \int_M^{M+M\delta} t^{p-1}dt \overset{\tau=t/M}{=}\\
	  &= M^p \int_{1-\delta}^1 \tau^{p-1}(\alpha \tau + \beta) d\tau - M^p \int_{1-\delta}^1 \tau^{p-1} d\tau + M^p \int_1^{1+\delta} \tau^{p-1} d\tau \overset{1/\delta}{\implies}\\
	  &\implies \fint_{1-\delta}^1 \tau^{p-1}(\alpha \tau + \beta) d\tau = \alpha \fint_{1-\delta}^1 \tau^{p} d\tau + \beta \fint_{1-\delta}^1 \tau^{p-1} d\tau = \fint_{1-\delta}^1 \tau^{p-1} d\tau - \fint_1^{1+\delta} \tau^{p-1} d\tau 
\end{align*}
The equation stemming from the orthogonality with $t^{q-1}$ is analogous. Therefore we obtained a nonhomogeneous linear system for $\alpha$ and $\beta$
\textbf{VA RESO MEGLIO}
\begin{equation}\label{system continuity}
	\begin{pmatrix}
		\fint_{1-\delta}^1 \tau^{p} d\tau &  \fint_{1-\delta}^1 \tau^{p-1} d\tau\\
		\fint_{1-\delta}^1 \tau^{q} d\tau & \fint_{1-\delta}^1 \tau^{q-1} d\tau
	\end{pmatrix}
	\begin{pmatrix}
		\alpha\\
		\beta
	\end{pmatrix}=
	\begin{pmatrix}
		\fint_{1-\delta}^1 \tau^{p-1} d\tau - \fint_1^{1+\delta} \tau^{p-1} d\tau\\
		\fint_{1-\delta}^1 \tau^{q-1} d\tau - \fint_1^{1+\delta} \tau^{q-1} d\tau
	\end{pmatrix}
\end{equation}
This system has a unique solution if and only if the determinant of the matrix is not 0. If we see it as a function of $\delta$ we can expand the terms in a Taylor series:
\begin{align*}
	& \fint_{1-\delta}^1 \tau^{p} d\tau \fint_{1-\delta}^1 \tau^{q-1} d\tau - \fint_{1-\delta}^1 \tau^{q} d\tau \fint_{1-\delta}^1 \tau^{p-1} d\tau=\\
	&=\left(1-\dfrac{p}{2}\delta + \dfrac{p(p-1)}{6}\delta^2 + o(\delta^2)\right) \left(1-\dfrac{q-1}{2}\delta + \dfrac{(q-1)(q-2)}{6}\delta^2 + o(\delta^2)\right) +\\
	&-\left(1-\dfrac{q}{2}\delta + \dfrac{q(q-1)}{6}\delta^2 + o(\delta^2)\right) \left(1-\dfrac{p-1}{2}\delta + \dfrac{(p-1)(p-2)}{6}\delta^2 + o(\delta^2)\right)=\\
	&=(1-1) + \delta \left(-\dfrac{q-1}{2} - \dfrac{p}{2} + \dfrac{p-1}{2} + \dfrac{q}{2} \right) \ldots\\
	&=\dfrac{p-q}{12}\delta^2 + o(\delta^2)
\end{align*}
therefore the determinant is always non 0.\\
The derivative of $G$ along $\eta$ is nonpositive because $u$ is supposed to be a maximizer, therefore
\begin{align*}
	0 &\geq \int_{M-M\delta}^{M+M\delta} G'(u(t))\eta(t)dt = -\int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt\, +\\
	  &+ \int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right)\left(\alpha \dfrac{t}{M}+\beta\right) dt + \int_M^{M+M\delta}dt = \\
	  &= -\int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt + \lambda_1 M^p \int_{1-\delta}^1 t^{p-1}(\alpha t + \beta) dt +\\
	  &+ \lambda_2 M^q \int_{1-\delta}^1 t^{q-1}(\alpha t + \beta) dt + M\delta
\end{align*}
Dividing by $M\delta$ and rearranging we obtain:
\begin{equation}\label{inequality continuity}
	\fint_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt \geq  1 + \lambda_1 M^{p-1} \fint_{1-\delta}^1 t^{p-1}(\alpha t + \beta) dt\, + \lambda_2 M^{q-1} \fint_{1-\delta}^1 t^{q-1}(\alpha t + \beta) dt
\end{equation}
We notice that the last two terms are exactly the one that appear in the orthogonality condition, therefore to understand their behavior as $\delta$ approaches 0 we need to study the right-hand side of the system \eqref{system continuity}. If we expand the first term in its Taylor series with respect to $\delta$ we have:
\begin{align*}
	\left(1-\dfrac{p-1}{2}\delta + o(\delta) \right) - \left(1+\dfrac{p-1}{2}\delta + o(\delta) \right) = -(p-1)\delta + o(\delta)
\end{align*}
and the same is for the other term. Since they both are of order $\delta$ if we let $\delta \rightarrow 0^+$ in \eqref{inequality continuity} we obtain
\begin{equation*}
	\lambda_1 M^{p-1} + \lambda_2 M^{q-1} \geq 1
\end{equation*}
Since the function $\lambda_1 t^{p-1}  + \lambda_2 t^{q-1}$ is strictly increasing (because $\lambda_1$ and $\lambda_2$ are both positive) $M \geq T$ which is absurd because we supposed that $M<T$.

Lastly we shall prove that multipliers $\lambda_1, \lambda_2$, and hence maximizer, are unique. For this proof it is convenient to express $u$ in a slightly different way:
\begin{equation*}
	u(t) = \dfrac{1}{d!}\left[ \Log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^d
\end{equation*} 
To emphasize that $u$ is parametrized by $c_1, c_2$ we may write $u(t;c_1,c_2)$. Now we define
\begin{equation*}
	f(c_1,c_2) = p\ \int_0^T t^{p-1}u(t;c1,c2)dt, \quad g(c_1,c_2) = q\ \int_0^T t^{q-1}u(t;c1,c2)dt
\end{equation*}
We want to highlight that, even if not explicit, also $T$ depends on $c_1$ and $c_2$. Nevertheless these functions are differentiable since both $T$ and $u$ are differentiable with respect to $(c_1,c_2)$, functions $t^{p-1}u$ and $t^{q-1}u$ and their derivatives are bounded in $(0,T)$. 
Our maximizer $u$ satisfies the constraints only if $f(c_1,c_2)=A^p, \, g(c_1,c_2) = B^q$. Therefore to prove uniqueness of the maximizer we need to show that level sets $\{f=A^p\}$ and $\{g=B^q\}$ intersect in only a point.\\
First of all we are studying endpoints. For example, if $c_2=0$:
\begin{align*}
	f(c_1,0) &= p\int_0^{1/{c_1}} t^{p-1}\dfrac{1}{d!}\left[-\log(c_1t)^{p-1}\right]^d dt \overset{\tau = c_1t}{=} \\
			 &= \dfrac{p(p-1)^d}{c_1^p d!}\int_0^1 \tau^{p-1}\left[-\log(\tau)\right]^d d\tau = \dfrac{\kappa_p^d}{c_1^p} = A^p \implies c_{1,f} = \dfrac{\kappa_p^{d/p}}{A}
\end{align*}
The same can be done for $g$ and setting $c_1=0$ thus we obtain four points
\begin{equation*}
	c_{1,f} = \dfrac{\kappa_p^{d/p}}{A},\ c_{1,g} = \left(\dfrac{p-1}{q}\right)^{d/q}\dfrac1{B},\ c_{2,f} = \left(\dfrac{q-1}{p}\right)^{d/p}\dfrac1{A},\ c_{2,g} = \dfrac{\kappa_q^{d/q}}{B}
\end{equation*}
In the regime we are considering one has that $c_{1,f} < c_{1,g}$ and $c_{2,f} > c_{2,g}$, indeed
\begin{align*}
	&c_{1,f} < c_{1,g} \iff \dfrac{\kappa_p^{d/p}}{A} < \left(\dfrac{p-1}{q}\right)^{d/q}\dfrac1{B} \iff \dfrac{B}{A} < \kappa_p^{d\left( \frac1{q}-\frac1{p}\right)}\left(\dfrac{p}{q}\right)^{d/q}\\
	&c_{2,f} > c_{2,g} \iff \left(\dfrac{q-1}{p}\right)^{d/p}\dfrac1{A} > \dfrac{\kappa_q^{d/q}}{B} \iff \dfrac{B}{A} > \kappa_q^{d\left( \frac1{p}-\frac1{q}\right)}\left(\dfrac{q}{p}\right)^{d/p}
\end{align*}
Since there is this dispositions of these points we expect there is an intersection between the level sets. Firstly we notice that, for every $c_1 \in (0,c_{1,f})$ there exist a unique value of $c_2$ for which $f(c_1,c_2) = A^p$. Indeed, from previous computations we notice that $f(c_1,0)$ is a decreasing function hence $f(c_1,0) > A^p$, while $\lim_{c_2 \rightarrow +\infty} f(c_1,c_2) = 0$. The uniqueness of this value follows from strict monotonicity of $f(c_1,\cdot)$, in fact:
\begin{equation}\label{df/dc1}
	\pfrac{f}{c_1}(c_1,c_2) = -\dfrac{p(p-1)}{(d-1)!}c_1^{p-2}\ \int_0^T \dfrac{t^{2(p-1)}}{(c_1t)^{p-1}+(c_2t)^{q-1}} \left[ -\log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^{d-1}dt
\end{equation}
is always strictly negative. We point out that the term $\frac{\partial T}{\partial c_1}(c_1,c_2)u(T;c_1,c_2)$ is zero because $u$ is 0 in $T$. The same is true for $g$, therefore on the interval $(0,c_{1,f})$ the level sets of $f$ and $g$ can be seen as the graph of two functions $\varphi, \gamma$. Since $\frac{\partial f}{\partial c_2}, \frac{\partial g}{\partial c_2} < 0$ for every $(c_1,c_2)$ from the implicit function theorem we have that $\varphi$ and  $\gamma$ are differentiable with respect to $c_1$.\\
{\large{\textbf{Possibile disegno??}}}\\
After defining $\varphi$ and $\gamma$ we want to prove that $(\varphi-\gamma)' < 0$. Still from the implicit function theorem we have
\begin{equation*}
	\begin{split}
		\dfrac{\mathrm{d}}{\mathrm{d} c_1}(\varphi - \gamma)(c_1) = -\dfrac{\pfrac{f}{c_1}(c_1,\varphi(c_1))}{\pfrac{f}{c_2}(c_1,\varphi(c_1))}  + 
		\dfrac{\pfrac{g}{c_1}(c_1,\gamma(c_1))}{\pfrac{g}{c_2}(c_1,\gamma(c_1))} < 0 \iff \\
		\pfrac{f}{c_1}(c_1,\varphi(c_1)) \pfrac{g}{c_2}(c_1,\gamma(c_1)) - \pfrac{f}{c_2}(c_1,\varphi(c_1)) \pfrac{g}{c_1}(c_1,\gamma(c_1)) > 0
	\end{split}
\end{equation*}
As for \eqref{df/dc1} the other derivatives are computed. To simplify the notation we define $h(t;c_1,c_2) = \frac{1}{(d-1)!}\frac{1}{(c_1t)^{p-1}+(c_2t)^{q-1}}\left[ -\log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^{d-1}$. From Fubini's theorem we can write the product of the integrals as a double integral
\begin{equation*}
	\begin{split}
		&p(p-1)q(q-1)c_1^{p-2}\gamma(c_1)^{q-2} \iint_{[0,T]^2} h(t;c_1,\varphi(c_2)) h(s;c_1,\gamma(c_2)) t^{2(p-1)} s^{2(q-1)} dtds -\\ &p(q-1)q(p-1)c_1^{p-2}\varphi(c_1)^{q-2} \iint_{[0,T]^2} h(t;c_1,\varphi(c_2)) h(s;c_1,\gamma(c_2)) t^{p+q-2} s^{p+q-2} dtds
	\end{split}
\end{equation*}
At the intersection point $\varphi(c_1)=\gamma(c_1)$ hence the sign of the previous expression depends only on the sign of
\begin{equation*}
	\begin{split}
		&\iint_{[0,T]^2} h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1))\left( t^{2(p-1)} s^{2(q-1)} - t^{p+q-2} s^{p+q-2} \right)dtds=\\
		&=\iint_{[0,T]^2} h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1)) t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds\\
	\end{split}
\end{equation*}
In order to simplify the notation once again we set $H(t,s;c_1) = h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1))$. Let $T_1 = [0,T]^2 \cap \{t>s\}$ and $T_2 = [0,T]^2 \cap \{t<s\}$. We can split the above integral in two parts
\begin{equation*}
	\begin{split}
		\iint_{T_1} H(t,s;c_1)t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds + \iint_{T_2} H(t,s;c_1)t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds
	\end{split}
\end{equation*}
We can exchange $t$ with $s$ in the second integral. With this change of variables the domain of integration becomes $T_1$ and since $H$ is symmetric in $t$ and $s$ we have that the previous quantity is equal to
\begin{equation*}
	\begin{split}
		&\iint_{T_1} H(t,s;c_1)\left( t^{p-2} s^{q-2} - t^{q-2} s^{p-2} \right) \left( t^p s^q - t^q s^p \right)dtds =\\
		&\iint_{T_1} H(t,s;c_1)\dfrac{1}{t^2 s^2}\left( t^p s^q - t^q s^p \right)^2 dtds
	\end{split}
\end{equation*}
which is strictly positive.

Now we are able to prove the uniqueness of multipliers.\\
First of all, since $(\varphi-\gamma)'<0$ whenever $\varphi(c_1) = \gamma(c_1)$, for every point of intersection there exist $\delta>0$ such that $\varphi(t) > \gamma(t)$ for $t \in (c_1 - \delta, c_1)$ while $\varphi(t) < \gamma(t)$ for $t \in (c_1, c_1 + \delta)$.\\
Define $c_1^* \coloneqq \sup \{c_1 \in [0,c_{1,f}] : \forall t \in [0,c_1] \ \varphi(t) \geq \gamma(t)\}$. This is an intersection point between $\varphi$ and $\gamma$ (if $\varphi(c_1^*) > \gamma(c_1^*)$ due to continuity there would be $\varepsilon > 0$ such that $\varphi(c_1^*+\varepsilon) > \gamma(c_1^*+\varepsilon)$ which contradicts the definition of $c_1^*$) and it is the first one, because we saw that after every intersection point there is an interval where $\varphi < \gamma$. Lastly, since $\varphi(0) > \gamma(0)$ and $\varphi(c_{1,f}) = 0 < \gamma(c_1,f)$ we have that $0 < c_1^* < c_{1,f}$.\\
Suppose now that there is a second point of intersection $\tilde{c}_1$ after the first one. Since immediately after $c_1^*$ we have that $\varphi$ becomes smaller than $\gamma$ this second point of intersection is given by $\tilde{c}_1 = \sup \{c_1 \in [c_1^*,c_{1,f}] : \forall t \in [c_1^*,c_1] \ \varphi(t) \leq \gamma(t)\}$. Considering that this is an intersection point, there exist an interval before $\tilde{c}_1$ where $\varphi$ is strictly grater than $\gamma$ which is absurd, hence $c_1^*$ is the only intersection point between $\varphi$ and $\gamma$.\\
Therefore $(c_1^*, \varphi(c_1^*) = c_2^*)$ is the unique pair of multipliers for which $p\int_0^T t^{p-1} u(t;c_1^*,c_2^*)dt = A^p,\ q\int_0^T t^{q-1} u(t;c_1^*,c_2^*)dt = B^q$ and in the end $u(t;c_1^*,c_2^*)$ is the unique maximizer for \textbf{CITARE PROBLEMA VARIAZIONALE}






\printbibliography


	

\end{document}32
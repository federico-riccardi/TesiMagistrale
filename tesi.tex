\documentclass[corpo=11pt, stile=classica, tipotesi=custom,
greek, evenboxes, english]{toptesi}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{hyperref}
\hypersetup{%
	pdfpagemode={UseOutlines},
	bookmarksopen,
	pdfstartview={FitH},
	colorlinks,
	linkcolor={blue},
	citecolor={blue},
	urlcolor={blue}
}

\usepackage{geometry} %for the margins
\newcommand\fillin[1][4cm]{\makebox[#1]{\dotfill}} %for the dotted line in the frontispiace

\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1} } %to vetical align numbers in tables, along the decimal dot

\usepackage{amsmath}







\usepackage{amsmath, amssymb, amsthm}
\usepackage{esint}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{systeme}
\usepackage{mathtools}
\hypersetup{colorlinks, linkcolor=blue, citecolor=blue}
\usepackage{biblatex}
\usepackage{cancel}
\addbibresource{bibliografia.bib}


\numberwithin{equation}{chapter}
\newtheorem{teo}{Theorem}[chapter] %in questo modo la numerazione ricomincia da capo ad ogni nuovo capitolo
\newtheorem{defi}[teo]{Definition}
\newtheorem{lem}[teo]{Lemma}
\newtheorem{cor}[teo]{Corollary}
\newtheorem{prop}[teo]{Proposition}
\newtheorem{es}[teo]{Example}

\newcommand{\R}{\mathbb{R}} %scorciatoia per R reali
\newcommand{\N}{\mathbb{N}} %scorciatoia per N naturali
\newcommand{\V}{\mathcal{V}} %STFT
\newcommand{\F}{\mathcal{F}} %Fourier transform
\newcommand{\C}{\mathbb{C}} %Complex numbers
\newcommand{\dxdo}{dxd\omega}
\newcommand{\notazione}{\underline{\textbf{Remark Notazionale}}}
\newcommand{\Log}{\ensuremath{\text{Log}_-}}
\newcommand{\finire}{\fbox{\LARGE DA FINIRE}}
\newcommand{\pfrac}[2]{\dfrac{\partial #1}{\partial #2}}

\begin{document}
\english
	
\input{./title.tex}

\tableofcontents

\ringraziamenti

\sommario

\chapter{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preliminaries}\label{chapter preliminaries}
In this first chapter we briefly recall some basics definition and results about functional analysis and Fourier transform. In section \ref{section basics of functional analysis} basic concepts about operators between Banach spaces are presented. In section \ref{section Fourier transform and its properties} Fourier transform is defined and essential properties are given.
\section{Basics of Functional Analysis}\label{section basics of functional analysis}
In this section we focus our attention on linear operator between Banach spaces. Across the section a generic Banach space will be denoted as $X$ (or $Y$) endowed with the norm $\| \cdot \|_X$. In case $X$ is an Hilbert space we will denote its inner product as $\langle \cdot, \cdot \rangle_X$.\\
A generic linear operator between two Banach spaces $X$ and $Y$ will be denoted as $T : X \rightarrow Y$. As a standard notation, the image of $x \in X$ through $T$ will be denoted as $T(x)$ or equivalently as $Tx$.
\begin{defi}\label{bounded operator}
	A linear operator $T : X \rightarrow Y$ is said to be \textbf{bounded} if there exist $C>0$ such that
	\begin{equation}\label{boundedness property}
		\| Tx \|_Y \leq C \| x \|_X \quad \forall x \in X
	\end{equation}
\end{defi}
For linear operator boundedness is strictly related to continuity as the subsequent theorem states
\begin{teo}\label{equivalente boundedness continuity}
	For a linear operator $T$ the following statements are equivalent:
	\begin{itemize}
		\item $T$ is continuous
		\item $T$ is bounded.
	\end{itemize}
\end{teo}
For the sake of completeness we mention that actually, for linear operators, boundedness is equivalent to uniform continuity.\\
After this we define the \emph{norm} of an operator
\begin{defi}\label{norm operator}
	Given a linear bounded operator $T$ we define its \textbf{norm} as the following number:
	\begin{equation*}
		\|T\| \coloneqq \inf\{C>0 : \| Tx \|_Y \leq C \| x \|_X \  \forall x \in X\} = \sup \left\{ \dfrac{\| Tx \|_Y}{\| x \|_X} : x \in X \setminus \{0\}\right\}
	\end{equation*}
\end{defi}
The proof of the equivalence between two definition is straightforward. We see that the norm of an operator is the best constant for which boundedness property \eqref{boundedness property} holds. Sometimes, in order to emphasize the spaces between which $T$ operates, we may write the norm of $T$ as $\| T \|_{X \rightarrow Y}$.\\
In the following we will mostly deal with $X$ and $Y$ being $L^2(\R^d)$, which is an Hilbert space. For operators between Hilbert spaces we can give the norm of an operator by means of the dual norm \textbf{CONTROLLARE}:
\begin{equation*}
	\| T \| = \sup\{\langle Tx, y \rangle_X : x,y \in X\}
\end{equation*}

An important class of operators is the class of \emph{compact operators}.
\begin{defi}\label{compact operator}
	A linear bounded operator $T$ is \textbf{compact} if for every bounded sequence $\{x_n\}_{n \in \N} \subset X$ the sequence of the images $\{Tx_n\}_{n \in \N} \subset Y$ has a converging subsequence.
\end{defi}
The property of compactness can be stated in multiple ways \textbf{SERVE SCRIVERLE?}

Now we suppose $X$ and $Y$ to be Hilbert spaces. Given a linear bounded operator $T : X \rightarrow Y$ we know that there exist a unique linear bonded operator $T^* : Y \rightarrow X$ such that:
\begin{equation*}
	\langle Tx, y \rangle_X = \langle x, T^* y \rangle_Y \quad \forall x \in X,\,y \in Y
\end{equation*}
$T^*$ is called the \textbf{adjoint} operator of $T$. In the particular case in which $T : X \rightarrow X$, if $T=T^*$ we say that $T$ is \textbf{self-adjoint}.\\
From now on we suppose that $X$ is over the field of complex numbers $\C$ and that $T : X \rightarrow X$.
\begin{defi}\label{spectrum def}
	The set $\sigma(T) = \{\lambda \in \C : T - \lambda I \text{ is not invertible}\}$ is called  the \textbf{spectrum} of $T$.
\end{defi}
For operators between finite-dimensional spaces (matrices) the spectrum is made up of \emph{eigenvalues}, those $\lambda \in \C$ such that $T-\lambda I$ is not injective, because in this case $T-\lambda I$ is not injective if and only if it is not surjective. On the other hand, when dealing with infinite-dimensional spaces, this is no more true. Eigenvalues are in the so called \emph{punctual spectrum}, which in general is just a part of the whole spectrum.\\
If an operator is compact or self-adjoint its spectrum has some additional properties.
\begin{teo}\label{Fredholm alternative}
	Let $T : X \rightarrow X$ be a compact operator. Then
\end{teo}



\begin{itemize}
	\item Norma operatoriale (FATTO)
	\item Operatori autoaggiunti? (FATTO)
	\item Operatori compatti (FATTO)
	\item Operatori di classe traccia
	\item Spettro operatori
	\item Operatori di Hilbert-Schmidt?
\end{itemize}
\section{Fourier Transform and its properties}\label{section Fourier transform and its properties}
\begin{defi}\label{def Fourier transform}
	Let $f \in L^1(\R^d)$. We define the \textbf{Fourier transform} of $f$ the function
	\begin{equation}\label{Fourier transform}
		\F f(\omega) = \hat{f}(\omega) \coloneqq \int_{\R^d} e^{-2 \pi i \omega \cdot t} f(t) dt
	\end{equation}
\end{defi}
It's straightforward to see that the definition is well-posed and that $\F f \in L^{\infty}(\R^d)$ with $\|\F f\|_{\infty} \leq \| f \|_1$. Therefore $\F$ can be seen as a linear operator between $L^1(\R^d)$ and $L^{\infty}(\R^d)$ with $\| \F \| = 1$ (from the previous inequality actually we saw that $\| \F \| \leq 1$ but if we take $f \geq 0$ a.e. we have that $\hat{f}(0) = \| f \|_1$ that gives us the equality).\\
If $f$ is in $L^2(\R^d)$, the integral in \eqref{Fourier transform} in general will not converge. Nevertheless we can define the Fourier transform of an $L^2$ function through a density argument. There are many dense subspaces in $L^2(\R^d)$ to do so. One possible choice is to use the Schwartz class $\mathcal{S}(\R^d)$. Another choice is to use $L^2(\R^d) \cap L^1(\R^d)$. On this space one can show that the Fourier transform is an isometry with respect to the $L^2$ norm and \textbf{CONTINUARE}.

	\begin{itemize}
		\item Defizione trasformata
		\item Disuguaglianza di Hausdorff-Young
		\item Teorema di Plancherel
		\item Formula di inversione
		\item Proprietà di decadimento e regolarità		
	\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Short-Time Fourier Transform}\label{chapter STFT}
\section{STFT}\label{section STFT}
The \emph{short-time Fourier transform} or \emph{STFT} is a powerful tool, introduced by Gabor in \textbf{AGGIUNGERE CITAZIONE E CONTROLLARE CHE SIA CORRETTA}, used to study properties of a signal locally both in time and frequency. The main idea behind the STFT is the following: if we want some information of the spectrum of a signal around a specific time, say $T$, we could choose an interval $(T-\Delta T, T + \Delta T)$ and take the Fourier transform of $f \chi_{(T-\Delta T, T + \Delta T)}$. Usually multiplying by a characteristic function will not give us a regular function (not even continuous) and in light of the duality between regularity and decay, the Fourier transform of $f \chi_{(T-\Delta T, T + \Delta T)}$ will not decay rapidly. Therefore a sharp cutoff in the time domain will result in a ``bad'' localization in the frequency domain. In order to avoid this kind of problems we could think to multiply the signal $f$ by a smooth function.
\begin{defi}\label{STFT def}
	Fix a function $\phi \neq 0$ called \emph{window function}. The \textbf{short-time Fourier transform} of a function $f$ with window $\phi$ is defined as
	\begin{equation}\label{STFT formula}
		\V_{\phi}f(x,\omega) = \int_{\R^d} f(t)\overline{\phi(t-x)}e^{-2 \pi i \omega \cdot t} dt, \quad (x,\omega) \in \R^{2d}
	\end{equation}
\end{defi}
In the above definition did not specify where $f$ and $phi$ are chosen. Since we are taking the Fourier transform of the function $f T_x\overline{\phi}$, the STFT is well defined whenever the Fourier transform of this function is. For example if both $f$ and $\phi$ are in $L^2(\R^d)$ then $f T_x\overline{\phi}$ is in $L^1(\R^d)$ for every $x \in \R^d$ and so the integral in \eqref{STFT formula} is defined. In this special case the STFT can be written as a scalar product:
\begin{equation*}
	\V_{\phi}f(x,\omega) = \int_{\R^d} f(t)\overline{\phi(t-x)}e^{-2 \pi i \omega \cdot t} dt = \langle f, M_{\omega} T_x \phi \rangle
\end{equation*}
In general, the STFT of $f$ with respect to $\phi$ will be defined whenever  $\langle f, M_{\omega} T_x \phi \rangle$ is an expression of some sort of duality. For example, if $f \in \mathcal{S}'(\R^d)$ and $\phi \in \mathcal{S}(\R^d)$ then $M_{\omega} T_x \overline{\phi} \in \mathcal{S}(\R^d)$, therefore $\langle f, M_{\omega} T_x \phi \rangle$ can be seen as the usual duality between tempered distributions and functions in the Schwartz space.\\
\textbf{AGGIUNGERE ALTRE DEFINIZIONI EQUIVALENTI DELLA STFT?}
\subsection{Properties of STFT}
In this section we will present and prove some properties about the STFT. An excellent reference is \cite{grochenig}.
\begin{teo}\label{orthogonality relations theorem}
	Let $f_1,f_2,\phi_1,\phi_2 \in L^2(\R^d$). Then $\V_{\phi_i}f_i \in L^2(\R^{2d})$ and the following holds:
	\begin{equation}\label{orthogonality relation formula}
		\langle \V_{\phi_1} f_1, \V_{\phi_2} f_2 \rangle = \langle f_1, f_2 \rangle \overline{\langle \phi_1, \phi_2 \rangle}
	\end{equation}
\end{teo}
\begin{proof}
	\textbf{VA MESSA??}
\end{proof}
\begin{cor}
	If $f, \phi \in L^2(\R^d)$ then
	\begin{equation*}
		\| \V_{\phi} f\|_2 = \| f \|_2 \| \phi \|_2
	\end{equation*} 
	In particular if $\| \phi \|_2 = 1$ we see that $\V_{\phi}$ is an isometry from $L^2(\R^d)$ into $L^2(\R^{2d})$.
\end{cor}
\begin{proof}
	\textbf{VA MESSA??}
\end{proof}
From a direct computation one can see that the adjoint operator of the STFT operator $\V_{\phi}$ is given by the following expression:
\begin{equation}\label{STFT adjoint}
	\V_{\phi}^* g(t) = \int_{\R^{2d}} g(x,\omega) \phi(t-x) e^{2 \pi i \omega \cdot t} dxd\omega = \int_{\R^{2d}} g(x,\omega) M_{\omega}T_x \phi (t) dxd\omega\quad \forall g \in L^2(\R^{2d})
\end{equation}
This adjoint operator appears in the following nice property
\begin{teo}\label{inversion formula theorem}
	Let $f \in L^2(\R^d)$ and $\phi, \gamma \in L^2(\R^{2d})$ such that $\langle \phi, \gamma \rangle \neq 0$. Then:
	\begin{equation}\label{inversion formula}
		f(t) = \dfrac{1}{\langle \phi, \gamma \rangle} \V_{\gamma}^* \V_{\phi} f(t) = \dfrac{1}{\langle \phi, \gamma \rangle} \int_{\R^{2d}} \V_{\phi}f(x,\omega)M_{\omega}T_x \gamma (t) dxd\omega \quad \forall t \in \R^d
	\end{equation}
\end{teo}
\begin{proof}
	\textbf{VA MESSA??}
\end{proof}
Therefore the adjoint operator $\V_{\gamma}^*$ acts, in some sense, as an inverse operator. This will be of paramount importance in the following.
\begin{itemize}
	\item Relazione di ortogonalità
	\item Formula di inversione
\end{itemize}
\section{Fock Space and Bargmann Transform}\label{section Fock Space and Bargmann transform}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Uncertainty principles}\label{chapter uncertainty principles}
\section{Heisenberg's uncertainty principle}\label{section Heisenberg's UP}
\section{Donoho-Stark's uncertainty principle}\label{section Donoho-Stark's UP}
\section{Lieb's uncertainty principle}\label{section Lieb's UP}
\section{Nicola-Tilli's uncertainty principle or Faber-Krahn Inequality for the STFT}\label{section Faber-Krahn inequality fot STFT}
Theorem from \cite{nicolatilli_fk}
\begin{teo}\label{faberkrahn}
	For every $f \in L^2(\R^d)$ such that $\|f\|_{L^2} = 1$ and every measurable subset $\Omega \subset \R^{2d}$ with finite measure we have
	\begin{equation*}
		\int_{\Omega}  |\V f(x,\omega)|^2 \dxdo \leq G(|\Omega|)
	\end{equation*}
	where $G(s)$ is given by
	\begin{equation}\label{G}
		G(s) \coloneqq \int_0^s e^{\left(-d!\tau\right)^{1/d}} d\tau
	\end{equation}
\end{teo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Localization Operators}\label{chapter localization operators}
\begin{itemize}
	\item Definizione
	\item Operatori di proiezione
	\item Operatori di localizzazione di Daubechies
	\item Proprietà di limitatezza e compattezza
	\item Autovalori e autofunzioni
\end{itemize}

\chapter{Recent results}\label{chapter recent results}
\section{Norm of localization operators: results from Nicola-Tilli}\label{section norm of localization operators}
\section{Generic case}
Let's now consider the case where both $p$ and $q$ are neither 1 or $+\infty$. The result presented in \cite{nicolatilli_norm} include the case ...
\begin{equation*}
	\| L_F\|_{L_2 \rightarrow L_2} \leq \min\{\kappa_p^{d\kappa_p}A, \, \kappa_q^{d\kappa_q}B\}
\end{equation*}
Suppose that the minimum is given by $\kappa_p^{d\kappa_p}A$, therefore
\begin{equation*}
	\kappa_p^{d\kappa_p}A \leq \kappa_q^{d\kappa_q}B \iff \dfrac{B}{A} \geq \left(\dfrac{\kappa_p^{\kappa_p}}{\kappa_q^{\kappa_q}}\right)^d
\end{equation*}
We can check if the solution of the problem with just the $L^p$ bound solves also the problem with both bounds, that is $F\|_{L^q} \leq B$, where $F$ is given by ...
\begin{align*}
	\| F \|_{L^q}^q &= \int_{\R^{2d}} |F(z)|^q dz = ... = \lambda^q \left(\dfrac{p-1}{q}\right)^d
\end{align*}
Since we want $F$ to satisfy the $L^q$ constraint we should have
\begin{equation*}
	\dfrac{B}{A} \geq \kappa_p^{d\left(\frac1q - \frac1p\right)}\left(\dfrac{p}{q}\right)^{\frac{d}{q}}
\end{equation*}
It would be nice if this bound was less restrictive than the first one. Unfortunately that's not the case, in fact it's always true that
\begin{equation*}
	\left(\dfrac{p'}{q'}\right)^{\frac1{q'}} \left(\dfrac{p}{q}\right)^{\frac1q} \geq 1
\end{equation*}

Following the path in \cite{nicolatilli_norm} we obtain ...\\
\begin{equation*}
	G'(u(t)) = \lambda_1 t^{p-1} + \lambda_2 t^{q-1} \implies u(t) = \dfrac{1}{d!}\left[-\log\left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right)\right]^d, \ t \in (0,M)
\end{equation*}
Our main goal now is to show that multipliers $\lambda_1, \lambda_2$ are unique and both positive.

The easiest fact to prove is that both multipliers are not 0. In fact if one, say $\lambda_2$, was 0, we would obtain that the solution of our problem is the same as the one with just the $L^p$ bound. But we already know that this function does not satisfy the $L^q$ constraint hence it is impossible that $\lambda_2=0$.

Suppose now that one of the multipliers, say always $\lambda_2$, is negative. Consider an interval $[a,b] \subset (0,M)$ and a variation $\eta \in L^{\infty}(0,M)$ supported in $[a,b]$. Thanks to the Gram-Schmidt process we can construct a variation orthogonal to $t^{p-1}$. Since $\eta$ is arbitrary we can suppose that it is not orthogonal to $t^{q-1}$, in particular we can suppose that $\int_{a}^{b}t^{q-1}\eta(t)dt <0$. Therefore the directional derivative of $G$ along $\eta$ is:
\begin{align*}
	\int_{a}^{b} G'(u(t))\eta(t)dt &= \int_{a}^{b} (\lambda_1 t^{p-1} + \lambda_2 t^{q-1})\eta(t)dt = \\
									   &= \lambda_2 \int_{a}^{b} t^{q-1} \eta(t)dt > 0
\end{align*}
which contradicts the fact that $u$ is a maximizer.

Now that we now that both multipliers are positive we can prove that $u$ is continuous, which is equivalent to say that $M=T$, where $T$ is the unique positive number such that $\lambda_1 T^{p-1} + \lambda_2 T^{q-1} = 1$ (uniqueness of $T$ follows from the positivity of multipliers).\\
We start supposing that $M < T$ which means that $\lim_{t \rightarrow M^-} u(t) > 0$. Consider the following variation 
\begin{equation*}
	\eta(t) = \left\{
	\begin{aligned}
		-1 + \alpha \frac{t}{M} + \beta,\quad & t \in (M-M\delta,M)\\
		1,\quad					   & t \in (M,M+M\delta)\\
		0,\quad				   & \text{otherwise}
	\end{aligned}\right.
\end{equation*}
where $\delta>0$ is small enough so that $M-M\delta >0$ and $M+M\delta < T$ while $\alpha$ and $\beta$ are constants, depending on $\delta$, to be found. Since we want this to be an admissible variation we need to impose that $\eta$ is orthogonal to $t^{p-1}$ and $t^{q-1}$. For example, the first condition is:
\begin{align*}
	0 &= \int_{M-M\delta}^{M+M\delta} t^{p-1} \eta(t) dt = -\int_{M-M\delta}^M t^{p-1}dt + \int_{M-M\delta}^M t^{p-1}\left(\alpha \frac{t}{M} + \beta\right) dt + \int_M^{M+M\delta} t^{p-1}dt \overset{\tau=t/M}{=}\\
	  &= M^p \int_{1-\delta}^1 \tau^{p-1}(\alpha \tau + \beta) d\tau - M^p \int_{1-\delta}^1 \tau^{p-1} d\tau + M^p \int_1^{1+\delta} \tau^{p-1} d\tau \overset{1/\delta}{\implies}\\
	  &\implies \fint_{1-\delta}^1 \tau^{p-1}(\alpha \tau + \beta) d\tau = \alpha \fint_{1-\delta}^1 \tau^{p} d\tau + \beta \fint_{1-\delta}^1 \tau^{p-1} d\tau = \fint_{1-\delta}^1 \tau^{p-1} d\tau - \fint_1^{1+\delta} \tau^{p-1} d\tau 
\end{align*}
The equation stemming from the orthogonality with $t^{q-1}$ is analogous. Therefore we obtained a nonhomogeneous linear system for $\alpha$ and $\beta$
\textbf{VA RESO MEGLIO}
\begin{equation}\label{system continuity}
	\begin{pmatrix}
		\fint_{1-\delta}^1 \tau^{p} d\tau &  \fint_{1-\delta}^1 \tau^{p-1} d\tau\\
		\fint_{1-\delta}^1 \tau^{q} d\tau & \fint_{1-\delta}^1 \tau^{q-1} d\tau
	\end{pmatrix}
	\begin{pmatrix}
		\alpha\\
		\beta
	\end{pmatrix}=
	\begin{pmatrix}
		\fint_{1-\delta}^1 \tau^{p-1} d\tau - \fint_1^{1+\delta} \tau^{p-1} d\tau\\
		\fint_{1-\delta}^1 \tau^{q-1} d\tau - \fint_1^{1+\delta} \tau^{q-1} d\tau
	\end{pmatrix}
\end{equation}
This system has a unique solution if and only if the determinant of the matrix is not 0. If we see it as a function of $\delta$ we can expand the terms in a Taylor series:
\begin{align*}
	& \fint_{1-\delta}^1 \tau^{p} d\tau \fint_{1-\delta}^1 \tau^{q-1} d\tau - \fint_{1-\delta}^1 \tau^{q} d\tau \fint_{1-\delta}^1 \tau^{p-1} d\tau=\\
	&=\left(1-\dfrac{p}{2}\delta + \dfrac{p(p-1)}{6}\delta^2 + o(\delta^2)\right) \left(1-\dfrac{q-1}{2}\delta + \dfrac{(q-1)(q-2)}{6}\delta^2 + o(\delta^2)\right) +\\
	&-\left(1-\dfrac{q}{2}\delta + \dfrac{q(q-1)}{6}\delta^2 + o(\delta^2)\right) \left(1-\dfrac{p-1}{2}\delta + \dfrac{(p-1)(p-2)}{6}\delta^2 + o(\delta^2)\right)=\\
	&=(1-1) + \delta \left(-\dfrac{q-1}{2} - \dfrac{p}{2} + \dfrac{p-1}{2} + \dfrac{q}{2} \right) \ldots\\
	&=\dfrac{p-q}{12}\delta^2 + o(\delta^2)
\end{align*}
therefore the determinant is always non 0.\\
The derivative of $G$ along $\eta$ is nonpositive because $u$ is supposed to be a maximizer, therefore
\begin{align*}
	0 &\geq \int_{M-M\delta}^{M+M\delta} G'(u(t))\eta(t)dt = -\int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt\, +\\
	  &+ \int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right)\left(\alpha \dfrac{t}{M}+\beta\right) dt + \int_M^{M+M\delta}dt = \\
	  &= -\int_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt + \lambda_1 M^p \int_{1-\delta}^1 t^{p-1}(\alpha t + \beta) dt +\\
	  &+ \lambda_2 M^q \int_{1-\delta}^1 t^{q-1}(\alpha t + \beta) dt + M\delta
\end{align*}
Dividing by $M\delta$ and rearranging we obtain:
\begin{equation}\label{inequality continuity}
	\fint_{M-M\delta}^M \left(\lambda_1 t^{p-1} + \lambda_2 t^{q-1}\right) dt \geq  1 + \lambda_1 M^{p-1} \fint_{1-\delta}^1 t^{p-1}(\alpha t + \beta) dt\, + \lambda_2 M^{q-1} \fint_{1-\delta}^1 t^{q-1}(\alpha t + \beta) dt
\end{equation}
We notice that the last two terms are exactly the one that appear in the orthogonality condition, therefore to understand their behavior as $\delta$ approaches 0 we need to study the right-hand side of the system \eqref{system continuity}. If we expand the first term in its Taylor series with respect to $\delta$ we have:
\begin{align*}
	\left(1-\dfrac{p-1}{2}\delta + o(\delta) \right) - \left(1+\dfrac{p-1}{2}\delta + o(\delta) \right) = -(p-1)\delta + o(\delta)
\end{align*}
and the same is for the other term. Since they both are of order $\delta$ if we let $\delta \rightarrow 0^+$ in \eqref{inequality continuity} we obtain
\begin{equation*}
	\lambda_1 M^{p-1} + \lambda_2 M^{q-1} \geq 1
\end{equation*}
Since the function $\lambda_1 t^{p-1}  + \lambda_2 t^{q-1}$ is strictly increasing (because $\lambda_1$ and $\lambda_2$ are both positive) $M \geq T$ which is absurd because we supposed that $M<T$.

Lastly we shall prove that multipliers $\lambda_1, \lambda_2$, and hence maximizer, are unique. For this proof it is convenient to express $u$ in a slightly different way:
\begin{equation*}
	u(t) = \dfrac{1}{d!}\left[ \Log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^d
\end{equation*} 
To emphasize that $u$ is parametrized by $c_1, c_2$ we may write $u(t;c_1,c_2)$. Now we define
\begin{equation*}
	f(c_1,c_2) = p\ \int_0^T t^{p-1}u(t;c1,c2)dt, \quad g(c_1,c_2) = q\ \int_0^T t^{q-1}u(t;c1,c2)dt
\end{equation*}
We want to highlight that, even if not explicit, also $T$ depends on $c_1$ and $c_2$. Nevertheless these functions are differentiable since both $T$ and $u$ are differentiable with respect to $(c_1,c_2)$, functions $t^{p-1}u$ and $t^{q-1}u$ and their derivatives are bounded in $(0,T)$. 
Our maximizer $u$ satisfies the constraints only if $f(c_1,c_2)=A^p, \, g(c_1,c_2) = B^q$. Therefore to prove uniqueness of the maximizer we need to show that level sets $\{f=A^p\}$ and $\{g=B^q\}$ intersect in only a point.\\
First of all we are studying endpoints. For example, if $c_2=0$:
\begin{align*}
	f(c_1,0) &= p\int_0^{1/{c_1}} t^{p-1}\dfrac{1}{d!}\left[-\log(c_1t)^{p-1}\right]^d dt \overset{\tau = c_1t}{=} \\
			 &= \dfrac{p(p-1)^d}{c_1^p d!}\int_0^1 \tau^{p-1}\left[-\log(\tau)\right]^d d\tau = \dfrac{\kappa_p^d}{c_1^p} = A^p \implies c_{1,f} = \dfrac{\kappa_p^{d/p}}{A}
\end{align*}
The same can be done for $g$ and setting $c_1=0$ thus we obtain four points
\begin{equation*}
	c_{1,f} = \dfrac{\kappa_p^{d/p}}{A},\ c_{1,g} = \left(\dfrac{p-1}{q}\right)^{d/q}\dfrac1{B},\ c_{2,f} = \left(\dfrac{q-1}{p}\right)^{d/p}\dfrac1{A},\ c_{2,g} = \dfrac{\kappa_q^{d/q}}{B}
\end{equation*}
In the regime we are considering one has that $c_{1,f} < c_{1,g}$ and $c_{2,f} > c_{2,g}$, indeed
\begin{align*}
	&c_{1,f} < c_{1,g} \iff \dfrac{\kappa_p^{d/p}}{A} < \left(\dfrac{p-1}{q}\right)^{d/q}\dfrac1{B} \iff \dfrac{B}{A} < \kappa_p^{d\left( \frac1{q}-\frac1{p}\right)}\left(\dfrac{p}{q}\right)^{d/q}\\
	&c_{2,f} > c_{2,g} \iff \left(\dfrac{q-1}{p}\right)^{d/p}\dfrac1{A} > \dfrac{\kappa_q^{d/q}}{B} \iff \dfrac{B}{A} > \kappa_q^{d\left( \frac1{p}-\frac1{q}\right)}\left(\dfrac{q}{p}\right)^{d/p}
\end{align*}
Since there is this dispositions of these points we expect there is an intersection between the level sets. Firstly we notice that, for every $c_1 \in (0,c_{1,f})$ there exist a unique value of $c_2$ for which $f(c_1,c_2) = A^p$. Indeed, from previous computations we notice that $f(c_1,0)$ is a decreasing function hence $f(c_1,0) > A^p$, while $\lim_{c_2 \rightarrow +\infty} f(c_1,c_2) = 0$. The uniqueness of this value follows from strict monotonicity of $f(c_1,\cdot)$, in fact:
\begin{equation}\label{df/dc1}
	\pfrac{f}{c_1}(c_1,c_2) = -\dfrac{p(p-1)}{(d-1)!}c_1^{p-2}\ \int_0^T \dfrac{t^{2(p-1)}}{(c_1t)^{p-1}+(c_2t)^{q-1}} \left[ -\log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^{d-1}dt
\end{equation}
is always strictly negative. We point out that the term $\frac{\partial T}{\partial c_1}(c_1,c_2)u(T;c_1,c_2)$ is zero because $u$ is 0 in $T$. The same is true for $g$, therefore on the interval $(0,c_{1,f})$ the level sets of $f$ and $g$ can be seen as the graph of two functions $\varphi, \gamma$. Since $\frac{\partial f}{\partial c_2}, \frac{\partial g}{\partial c_2} < 0$ for every $(c_1,c_2)$ from the implicit function theorem we have that $\varphi$ and  $\gamma$ are differentiable with respect to $c_1$.\\
{\large{\textbf{Possibile disegno??}}}\\
After defining $\varphi$ and $\gamma$ we want to prove that $(\varphi-\gamma)' < 0$. Still from the implicit function theorem we have
\begin{equation*}
	\begin{split}
		\dfrac{\mathrm{d}}{\mathrm{d} c_1}(\varphi - \gamma)(c_1) = -\dfrac{\pfrac{f}{c_1}(c_1,\varphi(c_1))}{\pfrac{f}{c_2}(c_1,\varphi(c_1))}  + 
		\dfrac{\pfrac{g}{c_1}(c_1,\gamma(c_1))}{\pfrac{g}{c_2}(c_1,\gamma(c_1))} < 0 \iff \\
		\pfrac{f}{c_1}(c_1,\varphi(c_1)) \pfrac{g}{c_2}(c_1,\gamma(c_1)) - \pfrac{f}{c_2}(c_1,\varphi(c_1)) \pfrac{g}{c_1}(c_1,\gamma(c_1)) > 0
	\end{split}
\end{equation*}
As for \eqref{df/dc1} the other derivatives are computed. To simplify the notation we define $h(t;c_1,c_2) = \frac{1}{(d-1)!}\frac{1}{(c_1t)^{p-1}+(c_2t)^{q-1}}\left[ -\log\left((c_1t)^{p-1} + (c_2t)^{q-1}\right) \right]^{d-1}$. From Fubini's theorem we can write the product of the integrals as a double integral
\begin{equation*}
	\begin{split}
		&p(p-1)q(q-1)c_1^{p-2}\gamma(c_1)^{q-2} \iint_{[0,T]^2} h(t;c_1,\varphi(c_2)) h(s;c_1,\gamma(c_2)) t^{2(p-1)} s^{2(q-1)} dtds -\\ &p(q-1)q(p-1)c_1^{p-2}\varphi(c_1)^{q-2} \iint_{[0,T]^2} h(t;c_1,\varphi(c_2)) h(s;c_1,\gamma(c_2)) t^{p+q-2} s^{p+q-2} dtds
	\end{split}
\end{equation*}
At the intersection point $\varphi(c_1)=\gamma(c_1)$ hence the sign of the previous expression depends only on the sign of
\begin{equation*}
	\begin{split}
		&\iint_{[0,T]^2} h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1))\left( t^{2(p-1)} s^{2(q-1)} - t^{p+q-2} s^{p+q-2} \right)dtds=\\
		&=\iint_{[0,T]^2} h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1)) t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds\\
	\end{split}
\end{equation*}
In order to simplify the notation once again we set $H(t,s;c_1) = h(t;c_1,\varphi(c_1)) h(s;c_1,\gamma(c_1))$. Let $T_1 = [0,T]^2 \cap \{t>s\}$ and $T_2 = [0,T]^2 \cap \{t<s\}$. We can split the above integral in two parts
\begin{equation*}
	\begin{split}
		\iint_{T_1} H(t,s;c_1)t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds + \iint_{T_2} H(t,s;c_1)t^{p-2}s^{q-2}\left( t^p s^q - t^q s^p \right)dtds
	\end{split}
\end{equation*}
We can exchange $t$ with $s$ in the second integral. With this change of variables the domain of integration becomes $T_1$ and since $H$ is symmetric in $t$ and $s$ we have that the previous quantity is equal to
\begin{equation*}
	\begin{split}
		&\iint_{T_1} H(t,s;c_1)\left( t^{p-2} s^{q-2} - t^{q-2} s^{p-2} \right) \left( t^p s^q - t^q s^p \right)dtds =\\
		&\iint_{T_1} H(t,s;c_1)\dfrac{1}{t^2 s^2}\left( t^p s^q - t^q s^p \right)^2 dtds
	\end{split}
\end{equation*}
which is strictly positive.

Now we are able to prove the uniqueness of multipliers.\\
First of all, since $(\varphi-\gamma)'<0$ whenever $\varphi(c_1) = \gamma(c_1)$, for every point of intersection there exist $\delta>0$ such that $\varphi(t) > \gamma(t)$ for $t \in (c_1 - \delta, c_1)$ while $\varphi(t) < \gamma(t)$ for $t \in (c_1, c_1 + \delta)$.\\
Define $c_1^* \coloneqq \sup \{c_1 \in [0,c_{1,f}] : \forall t \in [0,c_1] \ \varphi(t) \geq \gamma(t)\}$. This is an intersection point between $\varphi$ and $\gamma$ (if $\varphi(c_1^*) > \gamma(c_1^*)$ due to continuity there would be $\varepsilon > 0$ such that $\varphi(c_1^*+\varepsilon) > \gamma(c_1^*+\varepsilon)$ which contradicts the definition of $c_1^*$) and it is the first one, because we saw that after every intersection point there is an interval where $\varphi < \gamma$. Lastly, since $\varphi(0) > \gamma(0)$ and $\varphi(c_{1,f}) = 0 < \gamma(c_1,f)$ we have that $0 < c_1^* < c_{1,f}$.\\
Suppose now that there is a second point of intersection $\tilde{c}_1$ after the first one. Since immediately after $c_1^*$ we have that $\varphi$ becomes smaller than $\gamma$ this second point of intersection is given by $\tilde{c}_1 = \sup \{c_1 \in [c_1^*,c_{1,f}] : \forall t \in [c_1^*,c_1] \ \varphi(t) \leq \gamma(t)\}$. Considering that this is an intersection point, there exist an interval before $\tilde{c}_1$ where $\varphi$ is strictly grater than $\gamma$ which is absurd, hence $c_1^*$ is the only intersection point between $\varphi$ and $\gamma$.\\
Therefore $(c_1^*, \varphi(c_1^*) = c_2^*)$ is the unique pair of multipliers for which $p\int_0^T t^{p-1} u(t;c_1^*,c_2^*)dt = A^p,\ q\int_0^T t^{q-1} u(t;c_1^*,c_2^*)dt = B^q$ and in the end $u(t;c_1^*,c_2^*)$ is the unique maximizer for \textbf{CITARE PROBLEMA VARIAZIONALE}






\printbibliography


	

\end{document}32